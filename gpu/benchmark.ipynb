{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c024\n"
     ]
    }
   ],
   "source": [
    "!echo $SLURMD_NODENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the data from torchvision\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the training process\n",
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.679\n",
      "Finished Training\n",
      "time elapsed:  36.658716917037964\n"
     ]
    }
   ],
   "source": [
    "# Training on CPU\n",
    "starttime = time.time()\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "endtime = time.time()\n",
    "cpu_time = endtime - starttime\n",
    "print(\"time elapsed: \",cpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:48<00:00, 33.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.739803314208984, 33.853355884552, 33.78352475166321, 33.69594192504883, 33.825429916381836]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# profiling\n",
    "# Training on CPU\n",
    "\n",
    "# def trace_handler(p):\n",
    "#     output = p.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10)\n",
    "#     print(output)\n",
    "#     # p.export_chrome_trace(\"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
    "cpu_time=[0,0,0,0,0]\n",
    "\n",
    "for epoch in tqdm(range(5)):  # loop over the dataset multiple times\n",
    "    starttime = time.time()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        # running_loss += loss.item()\n",
    "        # if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "    endtime = time.time()\n",
    "    cpu_time[epoch] = endtime-starttime\n",
    "            \n",
    "print(cpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.77961115837097\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# get mean calc time for cpu\n",
    "print(np.mean(np.array(cpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# see if we have gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from torchvision\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,pin_memory=True,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, pin_memory=True,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.369\n",
      "Finished Training\n",
      "elapsed time: 14.47666597366333\n"
     ]
    }
   ],
   "source": [
    "# train on GPU\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    starttime = time.time()\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device,non_blocking=True), data[1].to(device,non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    endtime = time.time()\n",
    "\n",
    "print('Finished Training')\n",
    "gpu_time = endtime-starttime\n",
    "print('elapsed time:', gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.629579067230225, 13.603169441223145, 13.609471559524536, 13.628243684768677, 13.623639345169067]\n"
     ]
    }
   ],
   "source": [
    "# profiling\n",
    "# Training on GPU\n",
    "gpu_time = [0,0,0,0,0]\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    starttime = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        # running_loss += loss.item()\n",
    "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "    endtime = time.time()\n",
    "    gpu_time[epoch] = endtime-starttime\n",
    "# print('Finished Training')\n",
    "# endtime = time.time()\n",
    "# cpu_time = endtime - starttime\n",
    "print(gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu mean time:  33.77961115837097\n",
      "gpu mean time:  13.61882061958313\n",
      "acceleration:  2.4803624412085807\n"
     ]
    }
   ],
   "source": [
    "# Acceleration of using GPU\n",
    "gpu = np.mean(np.array(gpu_time))\n",
    "cpu = np.mean(np.array(cpu_time))\n",
    "print('cpu mean time: ',cpu)\n",
    "print('gpu mean time: ',gpu)\n",
    "print(\"acceleration: \",cpu/gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "elapsed time per epoch (GPU): 0.002271890640258789\n"
     ]
    }
   ],
   "source": [
    "# train on GPU\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        starttime = time.time()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device,non_blocking=True), data[1].to(device,non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        # running_loss += loss.item()\n",
    "        # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #     running_loss = 0.0\n",
    "        endtime = time.time()\n",
    "\n",
    "print('Finished Training')\n",
    "gpu_time_per_epoch = endtime-starttime\n",
    "print('elapsed time per epoch (GPU):', gpu_time_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Redo the preparation to train again on CPU and compare using pytorch profiling utils\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "# define CNN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                               aten::mkldnn_convolution        34.94%     117.994ms        34.98%     118.117ms       9.843ms            12  \n",
      "                          aten::max_pool2d_with_indices        19.10%      64.491ms        19.10%      64.491ms       5.374ms            12  \n",
      "                             aten::convolution_backward        18.31%      61.822ms        18.35%      61.973ms       5.164ms            12  \n",
      "                                        aten::clamp_min         7.22%      24.380ms         7.22%      24.380ms       1.016ms            24  \n",
      "                                            aten::fill_         6.92%      23.359ms         6.92%      23.359ms     556.167us            42  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         3.16%      10.676ms         3.21%      10.832ms       1.805ms             6  \n",
      "                                          ProfilerStep*         2.71%       9.145ms        99.97%     337.544ms      56.257ms             6  \n",
      "                               aten::threshold_backward         1.54%       5.209ms         1.54%       5.209ms     217.042us            24  \n",
      "                 aten::max_pool2d_with_indices_backward         0.92%       3.095ms         1.52%       5.133ms     427.750us            12  \n",
      "                                Optimizer.step#SGD.step         0.77%       2.600ms         1.40%       4.735ms     789.167us             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 337.658ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train on CPU\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10)\n",
    "    print(output)\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=2,\n",
    "        warmup=2,\n",
    "        active=6,\n",
    "        repeat=1),\n",
    "    on_trace_ready=trace_handler,\n",
    "    with_stack=True\n",
    "    ) as profiler:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs= net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            profiler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile GPU codes\n",
    "# GPU preparation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,pin_memory=True,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, pin_memory=True,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        37.90%      46.138ms        37.92%      46.158ms       7.693ms       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                                          ProfilerStep*        25.80%      31.412ms        82.16%     100.020ms      16.670ms       0.000us         0.00%       8.383ms       1.397ms             6  \n",
      "                                       cudaLaunchKernel         7.91%       9.626ms         7.91%       9.626ms      18.231us       0.000us         0.00%       0.000us       0.000us           528  \n",
      "autograd::engine::evaluate_function: NllLossBackward...         5.38%       6.545ms         5.86%       7.135ms       1.189ms       0.000us         0.00%      56.000us       9.333us             6  \n",
      "                                Optimizer.step#SGD.step         3.34%       4.066ms         8.99%      10.940ms       1.823ms       0.000us         0.00%     440.000us      73.333us             6  \n",
      "                                             aten::add_         2.11%       2.569ms         4.03%       4.906ms      37.167us       1.000ms         4.33%       1.000ms       7.576us           132  \n",
      "                                            aten::addmm         1.15%       1.396ms         1.81%       2.200ms     122.222us       1.043ms         4.52%       1.043ms      57.944us            18  \n",
      "                             aten::convolution_backward         1.14%       1.393ms         3.14%       3.825ms     318.750us       8.453ms        36.63%       9.829ms     819.083us            12  \n",
      "                                             aten::mul_         1.10%       1.338ms         2.03%       2.473ms      41.217us     144.000us         0.62%     144.000us       2.400us            60  \n",
      "                                              aten::sum         0.96%       1.169ms         1.46%       1.775ms      59.167us       1.770ms         7.67%       1.770ms      59.000us            30  \n",
      "                                               aten::mm         0.84%       1.019ms         1.38%       1.685ms      46.806us     987.000us         4.28%     987.000us      27.417us            36  \n",
      "                                aten::cudnn_convolution         0.80%     969.000us         1.59%       1.938ms     161.500us       4.141ms        17.94%       4.141ms     345.083us            12  \n",
      "                                        aten::clamp_min         0.60%     736.000us         1.00%       1.217ms      50.708us     504.000us         2.18%     504.000us      21.000us            24  \n",
      "                               aten::threshold_backward         0.60%     729.000us         0.99%       1.205ms      50.208us     770.000us         3.34%     770.000us      32.083us            24  \n",
      "autograd::engine::evaluate_function: torch::autograd...         0.58%     712.000us         1.21%       1.475ms      24.583us       0.000us         0.00%       0.000us       0.000us            60  \n",
      "                                            aten::empty         0.56%     678.000us         0.56%     678.000us       7.533us       0.000us         0.00%       0.000us       0.000us            90  \n",
      "                                                aten::t         0.52%     627.000us         0.92%       1.116ms      12.400us       0.000us         0.00%       0.000us       0.000us            90  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.50%     614.000us         3.66%       4.460ms     247.778us       0.000us         0.00%       1.381ms      76.722us            18  \n",
      "                          aten::max_pool2d_with_indices         0.49%     602.000us         0.71%     869.000us      72.417us     653.000us         2.83%     653.000us      54.417us            12  \n",
      "                      Optimizer.zero_grad#SGD.zero_grad         0.46%     558.000us         0.47%     575.000us      95.833us       0.000us         0.00%       0.000us       0.000us             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 121.731ms\n",
      "Self CUDA time total: 23.078ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train on GPU\n",
    "# profiler\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=20)\n",
    "    print(output)\n",
    "\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    with torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=2,\n",
    "        warmup=2,\n",
    "        active=6,\n",
    "        repeat=1),\n",
    "    on_trace_ready=trace_handler,\n",
    "    with_stack=True\n",
    "    ) as profiler:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device,non_blocking=True), data[1].to(device,non_blocking=True)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            profiler.step()\n",
    "\n",
    "            # # print statistics\n",
    "            # running_loss += loss.item()\n",
    "            # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #     running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with no pin_memory and non_blocking\n",
    "# Profile GPU codes\n",
    "# GPU preparation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 80\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,pin_memory=False,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, pin_memory=False,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        46.32%      58.349ms        46.52%      58.595ms       9.766ms       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                                          ProfilerStep*        20.04%      25.247ms        87.45%     110.158ms      18.360ms       0.000us         0.00%       8.401ms       1.400ms             6  \n",
      "                                       cudaLaunchKernel         7.62%       9.593ms         7.62%       9.593ms      18.169us       0.000us         0.00%       0.000us       0.000us           528  \n",
      "                                Optimizer.step#SGD.step         3.28%       4.134ms         8.73%      10.991ms       1.832ms       0.000us         0.00%     441.000us      73.500us             6  \n",
      "                                        cudaMemcpyAsync         2.17%       2.730ms         2.17%       2.730ms     227.500us       0.000us         0.00%       0.000us       0.000us            12  \n",
      "                                             aten::add_         2.03%       2.561ms         3.89%       4.903ms      37.144us       1.000ms         4.33%       1.000ms       7.576us           132  \n",
      "                             aten::convolution_backward         1.14%       1.431ms         3.08%       3.876ms     323.000us       8.467ms        36.64%       9.838ms     819.833us            12  \n",
      "                                             aten::mul_         1.08%       1.357ms         1.97%       2.477ms      41.283us     144.000us         0.62%     144.000us       2.400us            60  \n",
      "                                            aten::addmm         1.06%       1.337ms         1.70%       2.139ms     118.833us       1.041ms         4.50%       1.041ms      57.833us            18  \n",
      "                                              aten::sum         0.94%       1.190ms         1.42%       1.793ms      59.767us       1.764ms         7.63%       1.764ms      58.800us            30  \n",
      "                                               aten::mm         0.84%       1.057ms         1.36%       1.715ms      47.639us     987.000us         4.27%     987.000us      27.417us            36  \n",
      "                                aten::cudnn_convolution         0.77%     976.000us         1.53%       1.928ms     160.667us       4.155ms        17.98%       4.155ms     346.250us            12  \n",
      "                                  cudaStreamSynchronize         0.71%     896.000us         0.71%     896.000us      74.667us       0.000us         0.00%       0.000us       0.000us            12  \n",
      "                                            aten::empty         0.60%     756.000us         0.60%     756.000us       7.412us       0.000us         0.00%       0.000us       0.000us           102  \n",
      "                                        aten::clamp_min         0.60%     754.000us         0.99%       1.243ms      51.792us     503.000us         2.18%     503.000us      20.958us            24  \n",
      "                               aten::threshold_backward         0.59%     743.000us         0.97%       1.228ms      51.167us     773.000us         3.34%     773.000us      32.208us            24  \n",
      "autograd::engine::evaluate_function: torch::autograd...         0.58%     736.000us         1.19%       1.505ms      25.083us       0.000us         0.00%       0.000us       0.000us            60  \n",
      "                                      aten::convolution         0.52%     654.000us         2.76%       3.477ms     289.750us       0.000us         0.00%       4.858ms     404.833us            12  \n",
      "                                                aten::t         0.50%     634.000us         0.91%       1.145ms      12.722us       0.000us         0.00%       0.000us       0.000us            90  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.47%     590.000us         3.55%       4.473ms     248.500us       0.000us         0.00%       1.380ms      76.667us            18  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 125.965ms\n",
      "Self CUDA time total: 23.111ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train on GPU\n",
    "# profiler\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=20)\n",
    "    print(output)\n",
    "\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    with torch.profiler.profile(\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=2,\n",
    "        warmup=2,\n",
    "        active=6,\n",
    "        repeat=1),\n",
    "    on_trace_ready=trace_handler,\n",
    "    with_stack=True\n",
    "    ) as profiler:\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            profiler.step()\n",
    "\n",
    "            # # print statistics\n",
    "            # running_loss += loss.item()\n",
    "            # if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            #     running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
